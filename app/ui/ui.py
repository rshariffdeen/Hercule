import asyncio
import queue
import threading
import time
import traceback
from asyncio import AbstractEventLoop
from concurrent.futures import ThreadPoolExecutor
from os.path import join
from typing import Any, Iterable
from typing import Dict
from typing import List
from typing import Optional
from typing import Tuple

from textual._on import on
from textual.app import App
from textual.app import ComposeResult
from textual.events import Key
from textual.reactive import Reactive
from textual.widget import Widget
from textual.widgets import DataTable
from textual.widgets import Footer
from textual.widgets import Header
from textual.widgets import RichLog
from textual.widgets import Static
from textual.widgets._data_table import ColumnKey

from app.core import definitions
from app.core import emitter
from app.core import main
from app.core import utilities
from app.core import values
from app.core import writer
from app.ui.messages import JobAllocate
from app.ui.messages import JobFinish
from app.ui.messages import JobMount
from app.ui.messages import Write
from app.tools.codeql import precompile_queries

all_subjects_id = "all_subjects"
finished_subjects_id = "finished_subjects"
error_subjects_id = "error_subjects"
running_subjects_id = "running_subjects"

log_map: Dict[str, RichLog] = {}

TaskList = Iterable[ str ]


job_condition = threading.Condition()

Result = Tuple[str, str, Dict[str,str]]


class Hercule(App[List[Result]]):
    """The main window"""

    COLUMNS: Dict[str, Dict[str, ColumnKey]] = {
        "ID": {},
        "Subject": {},
        definitions.UI_STARTED_AT: {},
        definitions.UI_STATUS: {},
        definitions.UI_DURATION: {},
    }

    SUB_TITLE = "Program Repair Framework"

    BINDINGS = [
        ("d", "toggle_dark", "Toggle dark mode"),
        ("a", "show_all_subjects", "Show All Subjects"),
        ("r", "show_running_subjects", "Show Running Subjects"),
        ("f", "show_finished_subjects", "Show Finished Subjects"),
        ("e", "show_error_subjects", "Show Erred Subjects"),
    ]

    tasks: Optional[TaskList]
    malicious_packages: Optional[List[str]]

    async def _on_exit_app(self) -> None:
        values.ui_active = False
        self.jobs_cancelled = True

        # Allow all processes to wake up and process that they are cancelled
        self.free_cpus = 10000

        with job_condition:
            job_condition.notify_all()
        for id, task in self.jobs.items():
            if not task.done():
                task.cancel()
                self.finished_subjects.append(
                    (id, "Cancelled", {})
                )
        self._return_value = self.finished_subjects
        return await super()._on_exit_app()

    def on_mount(self):
        self.selected_subject = None
        self.finished_subjects: List[Result] = []

        self.jobs_remaining_mutex = threading.Lock()
        self.jobs_remaining = 0
        self.jobs: Dict[str, asyncio.Future] = {}

        self.jobs_cancelled = False

        self.setup_resource_allocation()

        values.ui_active = True

        self.setup_column_keys()

        loop = asyncio.get_running_loop()
        loop.set_default_executor(ThreadPoolExecutor(max_workers=values.cpus + 1))
        asyncio.get_running_loop().run_in_executor(
            None,
            self.prepare_tasks_run,
            loop,
        )

    def setup_resource_allocation(self) -> None:
        self.free_cpus = values.cpus

        self.cpu_queue: queue.Queue[str] = queue.Queue(values.cpus + 1)
        for cpu in range(values.cpus):
            self.cpu_queue.put(str(cpu))

    def setup_column_keys(self) -> None:
        for table in self.query(DataTable):
            column_keys = table.add_columns(*Hercule.COLUMNS.keys())
            if not table.id:
                utilities.error_exit(
                    "CustomDataTable does not have ID. This should not happen"
                )
            for column_name, column_key in zip(Hercule.COLUMNS.keys(), column_keys):
                Hercule.COLUMNS[column_name][table.id] = column_key

    def prepare_tasks_run(self, loop: AbstractEventLoop):
        try:
            self.hide(self.query_one("#" + all_subjects_id))

            self.is_preparing = True

            self.show(log_map["root"])
            self.query_one(Static).update(
                "Hercule is precompiling queries"
            )
            tasks = []
            if self.tasks:
                tasks = list(
                    self.tasks
                )

            precompile_queries()
            
            for iteration,(dir_pkg) in enumerate(tasks):
                self.construct_job(str(iteration),dir_pkg)
            
            self.hide(self.query_one(Static))
            if not values.debug:
                self.hide(log_map["root"])
            self.is_preparing = False

            self.show(self.query_one("#" + all_subjects_id))
            self.jobs_remaining_mutex.acquire(blocking=True)
            self.jobs_remaining += len(tasks)
            self.jobs_remaining_mutex.release()

        except Exception as e:
            self.show(self.query_one(Static))
            self.query_one(Static).update(
                "{}\n{}".format(str(e), traceback.format_exc())
            )
            self.debug_print("I got exception {}".format(e))

    def change_table(self, new_id: str):
        if self.is_preparing:
            return
        self.debug_print("Changing table!")
        try:
            self.selected_table: DataTable

            self.hide(self.selected_table)

            self.selected_table = self.query_one(new_id, DataTable)

            self.show(self.selected_table)
        except Exception as e:
            self.debug_print(e)

    def action_show_finished_subjects(self):
        self.change_table("#" + finished_subjects_id)

    def action_show_running_subjects(self):
        self.change_table("#" + running_subjects_id)

    def action_show_all_subjects(self):
        self.change_table("#" + all_subjects_id)

    def action_show_error_subjects(self):
        self.change_table("#" + error_subjects_id)

    def construct_job(
        self,
        iteration:str,
        dir_pkg:str
    ):
        key = dir_pkg

        _ = self.query_one("#" + all_subjects_id, DataTable).add_row(
            iteration,
            dir_pkg,
            "N/A",
            "Allocated",
            "N/A",
            key=key,
        )

        self.post_message(JobMount(key))
        self.post_message(
            JobAllocate(
                iteration,
                dir_pkg
            )
        )

    @on(Key)
    async def handle_key_press(self, message: Key):
        if message.key == "escape":
            if self.selected_subject:
                self.hide(log_map[self.selected_subject])
            self.selected_subject = None

    @on(JobAllocate)
    async def on_job_allocate(self, message: JobAllocate):
        loop = asyncio.get_running_loop()

        def job_allocated_job():
            cpus: List[str] = []

            required_cpu_cores = 10

            self.update_status(
                message.dir_pkg,
                "Waiting for {} CPU core(s)".format(
                    required_cpu_cores
                ),
            )

            with job_condition:
                while (
                    self.free_cpus < required_cpu_cores
                ):
                    job_condition.wait()
                if self.jobs_cancelled:
                    self.finished_subjects.append(
                        (message.dir_pkg, "Cancelled", {}, {})
                    )
                    job_condition.notify(1)
                    return
                emitter.debug(
                    "Getting {} CPU cores".format(
                        required_cpu_cores
                    )
                )
                self.free_cpus = self.free_cpus - required_cpu_cores
                for _ in range(required_cpu_cores):
                    cpus.append(self.cpu_queue.get(block=True, timeout=None))
                if (
                    self.free_cpus > 0
                ):  # Try to wake up another thread if there are more free resources
                    job_condition.notify_all()

            values.job_identifier.set(message.dir_pkg)

            self.update_status(message.dir_pkg, "Running")

            start_time = int(time.time())
            
            row_data = (
                message.index,
                start_time,
                "Running",
                "None",
                "N/A",
            )

            running_row_key = self.query_one(
                "#" + running_subjects_id, DataTable
            ).add_row(
                *row_data,
                key=message.dir_pkg,
            )

            self.query_one("#" + all_subjects_id, DataTable).update_cell(
                message.dir_pkg,
                Hercule.COLUMNS[definitions.UI_STARTED_AT][all_subjects_id],
                start_time,
                update_width=True,
            )

            status = "Success"
            try:
                main.scan_package(message.dir_pkg,self.malicious_packages)
            except Exception as e:
                log_map[message.dir_pkg].write(traceback.format_exc())
                status = "Fail"
            finally:
                emitter.information(
                    "Finished execution for {}".format(message.identifier)
                )
                self.post_message(
                    JobFinish(
                        message.dir_pkg,
                        values.experiment_status.get(status),
                        row_data,
                        {} # TODO
                    )
                )
            with job_condition:
                for cpu in cpus:
                    self.cpu_queue.put(cpu)
                self.free_cpus += required_cpu_cores
                emitter.debug(
                    "Putting back {} CPU cores to the job queue".format(
                        required_cpu_cores
                    )
                )
                job_condition.notify_all()

        task_future = loop.run_in_executor(None, job_allocated_job)
        self.jobs[message.dir_pkg] = task_future

    def update_status(self, key: str, status: str):
        try:  # generally a running task will be updating its status
            self.query_one("#" + running_subjects_id, DataTable).update_cell(
                key,
                Hercule.COLUMNS[definitions.UI_STATUS][running_subjects_id],
                status,
                update_width=True,
            )
        except:
            pass
        self.query_one("#" + all_subjects_id, DataTable).update_cell(
            key,
            Hercule.COLUMNS[definitions.UI_STATUS][all_subjects_id],
            status,
            update_width=True,
        )

    @on(JobMount)
    async def on_mount_job(self, message: JobMount):
        id = message.key.split("/")[-1].replace(".", "_")
        log_map[id] = RichLog(highlight=True, markup=True, wrap=True, id=id + "_log")
        self.hide(log_map[id])
        self.debug_print("Mounting {}".format(id))
        text_log = log_map[id]
        await self.mount(text_log, before=self.query_one("#" + all_subjects_id))
        text_log.write("This is the textual log for {}".format(id))
        self.hide(text_log)

    @on(JobFinish)
    async def on_job_finish(self, message: JobFinish):
        def update_table(key, id: str, table: DataTable):
            table.update_cell(
                key,
                Hercule.COLUMNS[definitions.UI_STATUS][id],
                str(message.status),
                update_width=True,
            )
            table.sort(Hercule.COLUMNS["ID"][id])
            table.update_cell(
                key,
                Hercule.COLUMNS[definitions.UI_DURATION][id],
                "{} second(s)".format(0),
                update_width=True,
            )

        # self.update_status(message.key, str(message.status))
        try:
            finished_subjects_table = self.query_one(
                "#" + finished_subjects_id, DataTable
            )
            all_subjects_table = self.query_one("#" + all_subjects_id, DataTable)
            row_key = finished_subjects_table.add_row(
                *message.row_data,
                key=message.key,
            )
            update_table(row_key, finished_subjects_id, finished_subjects_table)

            update_table(row_key, all_subjects_id, all_subjects_table)

            if message.status != "success":
                error_subjects_table = self.query_one(
                    "#" + error_subjects_id, DataTable
                )
                row_key = error_subjects_table.add_row(
                    *message.row_data,
                    key=message.key,
                )
                update_table(row_key, error_subjects_id, error_subjects_table)

        except Exception as e:
            self.debug_print(str(e))

        self.jobs_remaining_mutex.acquire(blocking=True)
        self.jobs_remaining -= 1
        self.jobs_remaining_mutex.release()

        self.finished_subjects.append(
            (message.key, message.status, message.results)
        )

        if self.jobs_remaining == 0:
            self.debug_print("DONE!")
            if not values.debug:
                # Ensure that the job is not counted for twice
                if message.key in self.jobs:
                    del self.jobs[message.key]
                self.exit(self.finished_subjects)

    @on(Write)
    async def write_message(self, message: Write):
        if message.identifier in log_map:
            log_map[message.identifier].write(
                message.text,
                shrink=False,
                width=2000,
                scroll_end=(self.selected_subject == message.identifier),
                expand=True,
            )
        self.debug_print(message.text)

    def show(self, x: Widget) -> None:
        x.visible = True
        x.styles.height = "100%"
        x.styles.border = ("heavy", "orange")

    def hide(self, x: Widget) -> None:
        x.visible = False
        x.styles.height = "0%"
        x.styles.border = None

    @on(DataTable.RowHighlighted)
    async def on_data_table_row_highlighted(
        self, message: DataTable.RowHighlighted
    ) -> None:
        # self.debug_print("I am highlighting {}".format(message.row_key.value))
        # self.selected: Optional[str]
        if self.selected_subject is not None:
            self.hide(log_map[self.selected_subject])

        if (
            message
            and message.row_key
            and message.row_key.value
            and message.row_key.value in log_map
        ):
            self.selected_subject = message.row_key.value
            self.show(log_map[self.selected_subject])
            self.set_focus(log_map[self.selected_subject], scroll_visible=True)
            log_map[self.selected_subject].scroll_end(animate=False)
        else:
            self.debug_print("Info was not okay? {}".format(message.__dict__))

    def compose(self) -> ComposeResult:
        def create_table(id: str):
            table: DataTable = DataTable(id=id)
            table.cursor_type = "row"
            table.styles.border = ("heavy", "orange")
            return table

        """Create child widgets for the app."""
        yield Header()

        static_window = Static("Hercule is starting")
        static_window.styles.text_align = "center"
        static_window.styles.text_style = "bold italic"

        yield static_window

        all_subjects_table = create_table(all_subjects_id)
        yield all_subjects_table

        self.selected_table = all_subjects_table

        finished_subjects_table = create_table(finished_subjects_id)
        yield finished_subjects_table
        self.hide(finished_subjects_table)

        running_subjects_table = create_table(running_subjects_id)
        yield running_subjects_table
        self.hide(running_subjects_table)

        error_subjects_table = create_table(error_subjects_id)
        yield error_subjects_table
        self.hide(error_subjects_table)

        log_map["root"] = RichLog(highlight=True, markup=True, wrap=True, id="root_log")
        log_map["root"].styles.border = ("heavy", "orange")
        yield log_map["root"]
        if not values.debug:
            self.hide(log_map["root"])

        yield Footer()

    def action_toggle_dark(self) -> None:
        """Toggle dark mode."""
        self.dark: Reactive[bool]
        self.dark = not self.dark

    def debug_print(self, text: Any):
        if values.debug or self.is_preparing:
            log_map["root"].write(text, width=2000, expand=True)


app: Hercule


def post_write(text: str):
    message = Write(text=text, identifier=values.job_identifier.get("(Root)"))
    app.post_message(message)


def update_current_job(status: str):
    if not values.ui_active:
        return
    current_job = values.job_identifier.get("NA")
    if current_job != "NA":
        if app._thread_id != threading.get_ident():
            app.call_from_thread(lambda: app.update_status(current_job, status))
        else:
            app.update_status(current_job, status)


def setup_ui(tasks: Optional[TaskList] = None, malicious_packages: Optional[List[str]] = None):
    global app
    app = Hercule()
    app.tasks = tasks
    app.malicious_packages = malicious_packages
    experiment_results = app.run()
    print_results(experiment_results)
    return len(experiment_results) if experiment_results else 0


def print_results(experiment_results: Optional[List[Result]]):
    values.ui_active = False
    emitter.debug("The final results are {}".format(experiment_results))
    if experiment_results:
        summary_map = {}
        for experiment, status, results in experiment_results:
            emitter.information(
                "\t[framework] Experiment {} has final status {}\n".format(
                    experiment,
                    status
                )
            )

        aggregation_file = join(
            values.dir_results, "aggregated_summary_{}.json".format(time.time())
        )

        emitter.information(
            "\t[framework] Inserting an aggregation of the data at {}".format(
                aggregation_file
            )
        )

        writer.write_as_json(summary_map, aggregation_file)
