import os.path
import json
from os.path import join
import csv
from typing import Any
import sys
from multiprocessing import Pool
from os.path import join
import docker
import docker.errors

image_name = "mirchevmp/maloss"


def setup():
    client = docker.from_env()
    try:
        image = client.images.get(image_name)
    except docker.errors.ImageNotFound as e:
        print("Pulling the maloss image. Please wait...")
        try:
            image = client.images.pull(image_name)
        except docker.errors.APIError as e:
            print("Error pulling the image. Exiting...")
            exit(1)


def write_as_csv(data: Any, output_file_path: str):
    with open(output_file_path, "w", encoding="UTF8") as f:
        writer = csv.writer(f)
        for output in data:
            writer.writerow(output)


def read_json(file_path: str):
    json_data = None
    if os.path.isfile(file_path):
        with open(file_path, "r") as in_file:
            content = in_file.readlines()
            if len(content) > 1:
                content_str = " ".join([l.strip().replace("\n", "") for l in content])
                content = content_str
            json_data = json.loads(content)
    return json_data


def is_flagged(file_path: str):
    with open(file_path, "r") as f:
        contents = f.read()
        return "api_results {" in contents


def process(data):
    client = docker.from_env()
    pkg_name, dir_path, output_dir = data
    # print(pkg_name)
    pkg_path = f"{dir_path}/{pkg_name}"
    final_output = join("/opt/maloss/", output_dir)
    if not os.path.isdir(final_output):
        # print(pkg_name)
        # os.mkdir(final_output)
        scan_command = f"bash -c 'mkdir /home/maloss/output && timeout -k 10s 60s python main.py static -l python -d cache_dir -o /home/maloss/output -c /home/maloss/config/astgen_python_smt.config -n /home/maloss/{pkg_name} >> /dev/null 2>&1'"
        print(scan_command)
        container = client.containers.run(
            image_name,
            "sleep infinity",
            remove=True,
            detach=True,
        )
        os.system(f"docker cp {pkg_path} {container.id}:/home/maloss/{pkg_name} >> /dev/null 2>&1")
        res = container.exec_run(scan_command)
        os.system(f"docker cp {container.id}:/home/maloss/output {final_output} >> /dev/null 2>&1")
        # print(res)
        container.stop(timeout=5)

    if not os.path.exists(final_output):
        return (pkg_name, None, False)

    output_files = os.listdir(final_output)
    if len(output_files) == 0:
        return (pkg_name, None, False)

    for file in os.listdir(final_output):
        if is_flagged(join(final_output, file)):
            return (pkg_name, file, True)

    return (pkg_name, None, False)


def run(sym_args):
    if not sym_args:
        print("requires the path to the dir and the pkg name list")
        exit(1)
    dir_path = sym_args[0]
    pkg_list = sym_args[1]
    if not os.path.isdir(dir_path):
        print("path is invalid", dir_path)
        exit(1)
    if not os.path.isfile(pkg_list):
        print("path is invalid", pkg_list)
        exit(1)

    aggregated_data: list[tuple[str, str, str]] = [
        ("Package Name", "File Path", "Result")
    ]
    list_packages = [
        f
        for f in sorted(os.listdir(dir_path))
        if os.path.isfile(join(dir_path, f)) and ".json" not in f and ".txt" not in f
    ]
    filtered_pkg_list = []
    with open(pkg_list, "r") as _f:
        content = _f.readlines()
        filtered_pkg_list = [f.strip().replace("\n", "") for f in content]

    print(dir_path, len(list_packages))

    with Pool(20) as p:
        for res in p.map(
            process,
            [
                (pkg_name, dir_path, f"output_{pkg_name}")
                for pkg_name in list_packages
                if pkg_name in filtered_pkg_list
            ][:],
            chunksize=1,
        ):
            aggregated_data.append(res)

    write_as_csv(aggregated_data, f"{dir_path}/maloss_result.csv")


if __name__ == "__main__":
    setup()
    run(sys.argv[1:])
